{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lab: Building Advanced Transformers**\n",
    "\n",
    "**Estimated time needed:  30 minutes**  \n",
    "\n",
    "In this lab, you will implement and experiment with advanced Transformer models using Keras. \n",
    "\n",
    "**Learning objectives:** \n",
    "\n",
    "By the end of this lab, you will: \n",
    "\n",
    "- Implement advanced Transformer models using Keras. \n",
    "\n",
    "- Apply Transformers to real-world sequential data tasks. \n",
    "\n",
    "- Build, train, and evaluate Transformer models. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-by-Step Instructions: \n",
    "\n",
    "### Step 1: Import necessary libraries \n",
    "\n",
    "Before you start, you need to import the required libraries: TensorFlow and Keras. Keras is included within TensorFlow as `tensorflow.keras.`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-18.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-24.12.23-py2.py3-none-any.whl.metadata (876 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from tensorflow) (24.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-5.29.2-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.17.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.68.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting numpy<2.1.0,>=1.26.0 (from tensorflow)\n",
      "  Downloading numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.5)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.4/615.4 MB\u001b[0m \u001b[31m777.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-18.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (40.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.12.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.68.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.7.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-5.29.2-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading wrapt-1.17.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (391 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m391.8/391.8 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, pyarrow, protobuf, optree, opt-einsum, numpy, mdurl, markdown, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, ml-dtypes, markdown-it-py, h5py, rich, keras, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.12.23 gast-0.6.0 google-pasta-0.2.0 grpcio-1.68.1 h5py-3.12.1 keras-3.7.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 numpy-2.0.2 opt-einsum-3.4.0 optree-0.13.1 protobuf-5.29.2 pyarrow-18.1.0 rich-13.9.4 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.5.0 werkzeug-3.1.3 wrapt-1.17.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m111.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 tzdata-2024.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (2.0.2)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m114.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.0 scipy-1.14.1 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.55.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (165 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.1/165.1 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (24.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m110.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.2/326.2 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.55.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m108.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m121.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.9/106.9 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.55.3 kiwisolver-1.4.8 matplotlib-3.10.0 pillow-11.0.0 pyparsing-3.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow pyarrow \n",
    "%pip install pandas  \n",
    "%pip install scikit-learn \n",
    "%pip install matplotlib \n",
    "%pip install requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-26 12:58:15.141107: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-26 12:58:15.143641: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-26 12:58:15.147973: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-26 12:58:15.167362: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1735217895.203574      83 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1735217895.209298      83 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-26 12:58:15.260956: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "import requests\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Setup the Environment to generate synthetic stock price data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic stock_prices.csv created and loaded.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create a synthetic stock price dataset\n",
    "np.random.seed(42)\n",
    "data_length = 2000  # Adjust data length as needed\n",
    "trend = np.linspace(100, 200, data_length)\n",
    "noise = np.random.normal(0, 2, data_length)\n",
    "synthetic_data = trend + noise\n",
    "\n",
    "# Create a DataFrame and save as 'stock_prices.csv'\n",
    "data = pd.DataFrame(synthetic_data, columns=['Close'])\n",
    "data.to_csv('stock_prices.csv', index=False)\n",
    "print(\"Synthetic stock_prices.csv created and loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (1899, 100, 1)\n",
      "Shape of Y: (1899,)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset \n",
    "data = pd.read_csv('stock_prices.csv') \n",
    "data = data[['Close']].values \n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "# Prepare the data for training\n",
    "def create_dataset(data, time_step=1):\n",
    "    X, Y = [], []\n",
    "\n",
    "    for i in range(len(data)-time_step-1):\n",
    "        a = data[i:(i+time_step), 0]\n",
    "        X.append(a)\n",
    "        Y.append(data[i + time_step, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "time_step = 100\n",
    "X, Y = create_dataset(data, time_step)\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "print(\"Shape of X:\", X.shape) \n",
    "print(\"Shape of Y:\", Y.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "`tensorflow` is the main library for machine learning in Python.  \n",
    "\n",
    "`stock_prices.csv` is the data set that is loaded. \n",
    "\n",
    "`MinMaxScaler` method is used to normalize the data.  \n",
    "\n",
    "`create_dataset`method is used to prepare the data for training. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Implement Multi-Head Self-Attention \n",
    "\n",
    "Define the Multi-Head Self-Attention mechanism. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads=8): \n",
    "        super(MultiHeadSelfAttention, self).__init__() \n",
    "        self.embed_dim = embed_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.projection_dim = embed_dim // num_heads \n",
    "        self.query_dense = Dense(embed_dim) \n",
    "        self.key_dense = Dense(embed_dim) \n",
    "        self.value_dense = Dense(embed_dim) \n",
    "        self.combine_heads = Dense(embed_dim) \n",
    "\n",
    "\n",
    "    def attention(self, query, key, value): \n",
    "        score = tf.matmul(query, key, transpose_b=True) \n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) \n",
    "        scaled_score = score / tf.math.sqrt(dim_key) \n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1) \n",
    "        output = tf.matmul(weights, value) \n",
    "        return output, weights \n",
    "\n",
    "    def split_heads(self, x, batch_size): \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim)) \n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "\n",
    "    def call(self, inputs): \n",
    "        batch_size = tf.shape(inputs)[0] \n",
    "        query = self.query_dense(inputs) \n",
    "        key = self.key_dense(inputs) \n",
    "        value = self.value_dense(inputs) \n",
    "        query = self.split_heads(query, batch_size) \n",
    "        key = self.split_heads(key, batch_size) \n",
    "        value = self.split_heads(value, batch_size) \n",
    "        attention, _ = self.attention(query, key, value) \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3]) \n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim)) \n",
    "        output = self.combine_heads(concat_attention) \n",
    "        return output \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The MultiHeadSelfAttention layer implements the multi-head self-attention mechanism, which allows the model to focus on different parts of the input sequence simultaneously. \n",
    "\n",
    "- The attention parameter computes the attention scores and weighted sum of the values. \n",
    "\n",
    "- The split_heads parameter splits the input into multiple heads for parallel attention computation. \n",
    "\n",
    "- The call method applies the self-attention mechanism and combines the heads. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Implement Transformer block \n",
    "\n",
    "Define the Transformer block. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerBlock, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    "\n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code:\n",
    "\n",
    "- The TransformerBlock layer combines multi-head self-attention with a feed-forward neural network and normalization layers.  \n",
    "\n",
    "- Dropout is used to prevent overfitting. \n",
    "\n",
    "- The call method applies the self-attention, followed by the feedforward network with residual connections and layer normalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Implement Encoder Layer \n",
    "\n",
    "Define the Encoder layer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(EncoderLayer, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    "\n",
    " \n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The EncoderLayer is similar to the TransformerBlock but is a reusable layer in the Transformer architecture. \n",
    "\n",
    "- It consists of a MultiHeadSelfAttention mechanism followed by a feedforward neural network. \n",
    "\n",
    "- Both sub-layers have residual connections around them, and layer normalization is applied to the output of each sub-layer. \n",
    "\n",
    "- The call method applies the self-attention, followed by the feedforward network, with residual connections and layer normalization. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Implement Transformer encoder \n",
    "\n",
    "Define the Transformer Encoder. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-26 13:00:17.530305: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 128)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout \n",
    "\n",
    "class MultiHeadSelfAttention(Layer): \n",
    "    def __init__(self, embed_dim, num_heads=8): \n",
    "        super(MultiHeadSelfAttention, self).__init__() \n",
    "        self.embed_dim = embed_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.projection_dim = embed_dim // num_heads \n",
    "        self.query_dense = Dense(embed_dim) \n",
    "        self.key_dense = Dense(embed_dim) \n",
    "        self.value_dense = Dense(embed_dim) \n",
    "        self.combine_heads = Dense(embed_dim) \n",
    " \n",
    "\n",
    "    def attention(self, query, key, value): \n",
    "        score = tf.matmul(query, key, transpose_b=True) \n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) \n",
    "        scaled_score = score / tf.math.sqrt(dim_key) \n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1) \n",
    "        output = tf.matmul(weights, value) \n",
    "        return output, weights \n",
    "\n",
    "\n",
    "    def split_heads(self, x, batch_size): \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim)) \n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "\n",
    "\n",
    "    def call(self, inputs): \n",
    "        batch_size = tf.shape(inputs)[0] \n",
    "        query = self.query_dense(inputs) \n",
    "        key = self.key_dense(inputs) \n",
    "        value = self.value_dense(inputs) \n",
    "        query = self.split_heads(query, batch_size) \n",
    "        key = self.split_heads(key, batch_size) \n",
    "        value = self.split_heads(value, batch_size) \n",
    "        attention, _ = self.attention(query, key, value) \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3]) \n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim)) \n",
    "        output = self.combine_heads(concat_attention) \n",
    "        return output \n",
    "\n",
    "class TransformerBlock(Layer): \n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerBlock, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    " \n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) \n",
    "\n",
    "class TransformerEncoder(Layer): \n",
    "    def __init__(self, num_layers, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerEncoder, self).__init__() \n",
    "        self.num_layers = num_layers \n",
    "        self.embed_dim = embed_dim \n",
    "        self.enc_layers = [TransformerBlock(embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)] \n",
    "        self.dropout = Dropout(rate) \n",
    "\n",
    "    def call(self, inputs, training=False): \n",
    "        x = inputs \n",
    "        for i in range(self.num_layers): \n",
    "            x = self.enc_layers[i](x, training=training) \n",
    "        return x \n",
    "\n",
    "# Example usage \n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "inputs = tf.random.uniform((1, 100, embed_dim)) \n",
    "outputs = transformer_encoder(inputs, training=False)  # Use keyword argument for 'training' \n",
    "print(outputs.shape)  # Should print (1, 100, 128) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "The TransformerEncoder is composed of multiple TransformerBlock layers, implementing the encoding part of the Transformer architecture. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Build and Compile the Transformer model \n",
    "\n",
    "Integrate the Transformer Encoder into a complete model for sequential data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">793,088</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,801</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m793,088\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12800\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │        \u001b[38;5;34m12,801\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the necessary parameters \n",
    "\n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "# Define the Transformer Encoder \n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "\n",
    "# Build the model \n",
    "input_shape = (X.shape[1], X.shape[2]) \n",
    "inputs = tf.keras.Input(shape=input_shape) \n",
    "\n",
    "# Project the inputs to the embed_dim \n",
    "x = tf.keras.layers.Dense(embed_dim)(inputs) \n",
    "encoder_outputs = transformer_encoder(x) \n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "outputs = tf.keras.layers.Dense(1)(flatten) \n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "# Compile the model \n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "# Summary of the model \n",
    "model.summary() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The Transformer Encoder model defines the necessary parameters, flattens the output, and ends with a dense layer to produce the final output.  \n",
    "\n",
    "- The model is then compiled with the Adam optimizer and mean squared error loss. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Train the Transformer model \n",
    "\n",
    "Train the model on the prepared dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 1s/step - loss: 12.3501\n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.2252\n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.1917\n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.1656\n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.1638\n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 0.1586\n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 0.1496\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 0.1032\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.1163\n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0973\n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0852\n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0745\n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0832\n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.1508\n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0509\n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0472\n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 0.0519\n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 0.0520\n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0568\n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0359\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f49ac3acc50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "The model is trained on the normalized stock price data for 20 epochs with a batch size of 32. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Evaluate and Make Predictions \n",
    "\n",
    "Evaluate the model's performance and make predictions on the dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 304ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions \n",
    "predictions = model.predict(X) \n",
    "predictions = scaler.inverse_transform(predictions) \n",
    " \n",
    "\n",
    "# Plot the predictions \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.plot(data, label='True Data') \n",
    "plt.plot(np.arange(time_step, time_step + len(predictions)), predictions, label='Predictions') \n",
    "plt.xlabel('Time') \n",
    "plt.ylabel('Stock Price') \n",
    "plt.legend() \n",
    "plt.show() \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The model's predictions are transformed back to the original scale using the inverse transform of the scaler. \n",
    "\n",
    "- The true data and predictions are plotted to visualize the model's performance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercises: \n",
    "\n",
    " ### Exercise 1: Add dropout to the Transformer model \n",
    "\n",
    " **Objective: Understand how to add dropout layers to the Transformer model to prevent overfitting.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Add a dropout layer after the Flatten layer in the model. \n",
    "\n",
    "- Set the dropout rate to 0.5. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - loss: 6.8260\n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 1.4806\n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.7068\n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.3432\n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.1870\n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0794\n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0594\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0512\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0485\n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0361\n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0434\n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0310\n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0238\n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0228\n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0206\n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 1s/step - loss: 0.0209\n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0175\n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0166\n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0214\n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0180\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 291ms/step - loss: 0.0010\n",
      "Test loss: 0.0014153171796351671\n"
     ]
    }
   ],
   "source": [
    "## Write your code here.\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "# Add a dropout layer after the Flatten layer\n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs)\n",
    "dropout = Dropout(0.5)(flatten)\n",
    "outputs = tf.keras.layers.Dense(1)(dropout)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss: {loss}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "from tensorflow.keras.layers import Dropout \n",
    "\n",
    "  \n",
    "\n",
    "# Add a dropout layer after the Flatten layer \n",
    "\n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "\n",
    "dropout = Dropout(0.5)(flatten) \n",
    "\n",
    "outputs = tf.keras.layers.Dense(1)(dropout) \n",
    "\n",
    "  \n",
    "\n",
    "# Build the model \n",
    "\n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "  \n",
    "\n",
    "# Compile the model \n",
    "\n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "  \n",
    "\n",
    "# Train the model \n",
    "\n",
    "model.fit(X, Y, epochs=20, batch_size=32) \n",
    "\n",
    "  \n",
    "\n",
    "# Evaluate the model \n",
    "\n",
    "loss = model.evaluate(X, Y) \n",
    "\n",
    "print(f'Test loss: {loss}') \n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Experiment with different batch sizes \n",
    "\n",
    "**Objective: Observe the impact of different batch sizes on model performance.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Train the model with a batch size of 16. \n",
    "\n",
    "- Train the model with a batch size of 64. \n",
    "\n",
    "- Compare the training time and performance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 594ms/step - loss: 0.0205\n",
      "Epoch 2/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 594ms/step - loss: 0.0272\n",
      "Epoch 3/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 591ms/step - loss: 0.0305\n",
      "Epoch 4/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 587ms/step - loss: 0.0453\n",
      "Epoch 5/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 595ms/step - loss: 0.0260\n",
      "Epoch 6/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 588ms/step - loss: 0.0208\n",
      "Epoch 7/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 583ms/step - loss: 0.0189\n",
      "Epoch 8/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 596ms/step - loss: 0.0174\n",
      "Epoch 9/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 598ms/step - loss: 0.0207\n",
      "Epoch 10/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 595ms/step - loss: 0.0272\n",
      "Epoch 11/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 590ms/step - loss: 0.0293\n",
      "Epoch 12/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 587ms/step - loss: 0.0124\n",
      "Epoch 13/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 596ms/step - loss: 0.0208\n",
      "Epoch 14/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 600ms/step - loss: 0.0291\n",
      "Epoch 15/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 598ms/step - loss: 0.0276\n",
      "Epoch 16/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 592ms/step - loss: 0.0228\n",
      "Epoch 17/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 596ms/step - loss: 0.0131\n",
      "Epoch 18/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 598ms/step - loss: 0.0119\n",
      "Epoch 19/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 595ms/step - loss: 0.0109\n",
      "Epoch 20/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 590ms/step - loss: 0.0142\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 295ms/step - loss: 0.0063\n",
      "Test loss with batch size 16: 0.006181648001074791\n",
      "Epoch 1/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - loss: 0.0120\n",
      "Epoch 2/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - loss: 0.0051\n",
      "Epoch 3/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - loss: 0.0035\n",
      "Epoch 4/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - loss: 0.0032\n",
      "Epoch 5/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - loss: 0.0032\n",
      "Epoch 6/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - loss: 0.0027\n",
      "Epoch 7/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - loss: 0.0029\n",
      "Epoch 8/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - loss: 0.0029\n",
      "Epoch 9/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - loss: 0.0034\n",
      "Epoch 10/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - loss: 0.0035\n",
      "Epoch 11/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - loss: 0.0049\n",
      "Epoch 12/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - loss: 0.0044\n",
      "Epoch 13/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - loss: 0.0037\n",
      "Epoch 14/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 0.0025\n",
      "Epoch 15/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - loss: 0.0025\n",
      "Epoch 16/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - loss: 0.0027\n",
      "Epoch 17/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - loss: 0.0023\n",
      "Epoch 18/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 0.0025\n",
      "Epoch 19/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 0.0031\n",
      "Epoch 20/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - loss: 0.0032\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 298ms/step - loss: 0.0049\n",
      "Test loss with batch size 64: 0.002553064376115799\n"
     ]
    }
   ],
   "source": [
    "## Write your code here.\n",
    "# Train the model with batch size 16\n",
    "model.fit(X, Y, epochs=20, batch_size=16)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 16: {loss}')\n",
    "\n",
    "# Train the model with batch size 64\n",
    "model.fit(X, Y, epochs=20, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 64: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "# Train the model with batch size 16\n",
    "model.fit(X, Y, epochs=20, batch_size=16)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 16: {loss}')\n",
    "\n",
    "# Train the model with batch size 64\n",
    "model.fit(X, Y, epochs=20, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 64: {loss}')\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Use a different activation function \n",
    "\n",
    " **Objective: Understand how different activation functions impact the model performance.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Change the activation function of the Dense layer to `tanh`. \n",
    "\n",
    "- Train and evaluate the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 1s/step - loss: 0.2391\n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0307\n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 0.0107\n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 0.0070\n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0058\n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 0.0068\n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0029\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0029\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0025\n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0018\n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 0.0016\n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0022\n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0044\n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0015\n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0015\n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0024\n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0015\n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - loss: 0.0014\n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 0.0019\n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - loss: 0.0013\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 298ms/step - loss: 0.0038\n",
      "Test loss with tanh activation: 0.0024031540378928185\n"
     ]
    }
   ],
   "source": [
    "## Write your code here.\n",
    "# Change the activation function of the Dense layer to tanh\n",
    "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with tanh activation: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "# Change the activation function of the Dense layer to tanh\n",
    "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with tanh activation: {loss}')\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Congratulations on completing this lab! In this lab, you have built an advanced Transformer model using Keras and applied it to a time series forecasting task. You have learned how to define and implement multi-head self-attention, Transformer blocks, encoder layers, and integrate them into a complete Transformer model. By experimenting with different configurations and training the model, you can further improve its performance and apply it to various sequential data tasks. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "prev_pub_hash": "28ac4fd81c1d713f83dcd1cdf1d3383ad25ea92873288fe9e978e9a17b314709"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
